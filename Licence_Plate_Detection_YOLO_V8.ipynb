{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SachinShaju/tourism/blob/main/Licence_Plate_Detection_YOLO_V8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmM1dop72HfK",
        "outputId": "16b55adb-23a8-4de0-8ec9-3bb26a2f50a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Licence-Plate-Detection-using-YOLO-V8'...\n",
            "remote: Enumerating objects: 133, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 133 (delta 4), reused 8 (delta 3), pack-reused 117\u001b[K\n",
            "Receiving objects: 100% (133/133), 14.73 MiB | 18.76 MiB/s, done.\n",
            "Resolving deltas: 100% (34/34), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Arijit1080/Licence-Plate-Detection-using-YOLO-V8.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/Licence-Plate-Detection-using-YOLO-V8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TotCpH174BPu",
        "outputId": "79944763-8d67-41cc-f6d3-2e167898f83b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Licence-Plate-Detection-using-YOLO-V8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"I0RAXqmnUgYGQcDs9yUa\")\n",
        "project = rf.workspace(\"kitchen-hygiene\").project(\"kitchenhygiene\")\n",
        "dataset = project.version(2).download(\"yolov8\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i7nQY2yu4Ee3",
        "outputId": "479f9870-5377-4f70-8903-a09eef1b823e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.7-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi==2022.12.7 (from roboflow)\n",
            "  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chardet==4.0.0 (from roboflow)\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler==0.10.0 (from roboflow)\n",
            "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
            "Collecting idna==2.10 (from roboflow)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.4.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from roboflow) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.23.5)\n",
            "Collecting opencv-python-headless==4.8.0.74 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.8.0.74-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from roboflow) (9.4.0)\n",
            "Collecting pyparsing==2.4.7 (from roboflow)\n",
            "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from roboflow) (1.16.0)\n",
            "Collecting supervision (from roboflow)\n",
            "  Downloading supervision-0.16.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.2/72.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.10/dist-packages (from roboflow) (2.0.7)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from roboflow) (4.66.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from roboflow) (6.0.1)\n",
            "Collecting requests-toolbelt (from roboflow)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (1.1.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (4.43.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->roboflow) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->roboflow) (3.3.0)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from supervision->roboflow) (1.11.3)\n",
            "Installing collected packages: python-dotenv, pyparsing, opencv-python-headless, idna, cycler, chardet, certifi, supervision, requests-toolbelt, roboflow\n",
            "  Attempting uninstall: pyparsing\n",
            "    Found existing installation: pyparsing 3.1.1\n",
            "    Uninstalling pyparsing-3.1.1:\n",
            "      Successfully uninstalled pyparsing-3.1.1\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.8.1.78\n",
            "    Uninstalling opencv-python-headless-4.8.1.78:\n",
            "      Successfully uninstalled opencv-python-headless-4.8.1.78\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.4\n",
            "    Uninstalling idna-3.4:\n",
            "      Successfully uninstalled idna-3.4\n",
            "  Attempting uninstall: cycler\n",
            "    Found existing installation: cycler 0.12.1\n",
            "    Uninstalling cycler-0.12.1:\n",
            "      Successfully uninstalled cycler-0.12.1\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2023.7.22\n",
            "    Uninstalling certifi-2023.7.22:\n",
            "      Successfully uninstalled certifi-2023.7.22\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed certifi-2022.12.7 chardet-4.0.0 cycler-0.10.0 idna-2.10 opencv-python-headless-4.8.0.74 pyparsing-2.4.7 python-dotenv-1.0.0 requests-toolbelt-1.0.0 roboflow-1.1.7 supervision-0.16.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "cycler",
                  "pyparsing"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n",
            "[WARNING] we noticed you are downloading a `yolov8` datasets but you don't have `ultralytics` installed. Roboflow `.deploy` supports only models trained with `ultralytics==8.0.134`, to intall it `pip install ultralytics==8.0.134`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in KitchenHygiene-2 to yolov8:: 100%|██████████| 380296/380296 [00:07<00:00, 48799.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to KitchenHygiene-2 in yolov8:: 100%|██████████| 15220/15220 [00:03<00:00, 4825.67it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qd0UgEnF5KH8",
        "outputId": "974307bc-aaad-4515-c444-651b1a28d347"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics==8.0.3 (from -r requirements.txt (line 4))\n",
            "  Downloading ultralytics-8.0.3-py3-none-any.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.5/247.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hydra-core>=1.2.0 (from -r requirements.txt (line 5))\n",
            "  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.23.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (9.4.0)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (1.11.3)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (0.16.0+cu118)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (4.66.1)\n",
            "Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (2.14.1)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (1.5.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 23)) (0.12.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 26)) (7.34.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (5.9.5)\n",
            "Collecting thop>=0.1.1 (from -r requirements.txt (line 28))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Collecting GitPython>=3.1.24 (from -r requirements.txt (line 31))\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.4,>=2.2 (from hydra-core>=1.2.0->-r requirements.txt (line 5))\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.9.* (from hydra-core>=1.2.0->-r requirements.txt (line 5))\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.2.0->-r requirements.txt (line 5)) (23.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (1.1.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (0.10.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (4.43.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 11)) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 11)) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 11)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 11)) (2022.12.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 13)) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 13)) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 13)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 13)) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 13)) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 13)) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 13)) (2.1.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.59.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.5)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 22)) (2023.3.post1)\n",
            "Collecting jedi>=0.16 (from ipython->-r requirements.txt (line 26))\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 26)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 26)) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 26)) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 26)) (3.0.39)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 26)) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 26)) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 26)) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->-r requirements.txt (line 26)) (4.8.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython>=3.1.24->-r requirements.txt (line 31))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython>=3.1.24->-r requirements.txt (line 31))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.4.1->-r requirements.txt (line 18)) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->-r requirements.txt (line 26)) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->-r requirements.txt (line 26)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->-r requirements.txt (line 26)) (0.2.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.4.1->-r requirements.txt (line 18)) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->-r requirements.txt (line 13)) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 18)) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.4.1->-r requirements.txt (line 18)) (3.2.2)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=a3b47fb81195c23acacaf944f17ab15f297b76af0ef6289b6c7391520537f1f7\n",
            "  Stored in directory: /root/.cache/pip/wheels/12/93/dd/1f6a127edc45659556564c5730f6d4e300888f4bca2d4c5a88\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, smmap, omegaconf, jedi, hydra-core, gitdb, thop, GitPython, ultralytics\n",
            "Successfully installed GitPython-3.1.40 antlr4-python3-runtime-4.9.3 gitdb-4.0.11 hydra-core-1.3.2 jedi-0.19.1 omegaconf-2.3.0 smmap-5.0.1 thop-0.1.1.post2209072238 ultralytics-8.0.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Licence-Plate-Detection-using-YOLO-V8/ultralytics/yolo/v8/detect/train.py model=yolov8x.pt data=/content/Licence-Plate-Detection-using-YOLO-V8/KitchenHygiene-2/data.yaml epochs=10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dK5DpY9D5iiu",
        "outputId": "fae84521-cf43-4220-e6a1-ee5ab4d9b2ed"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1myolo/engine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8x.pt, data=/content/Licence-Plate-Detection-using-YOLO-V8/KitchenHygiene-2/data.yaml, epochs=10, patience=50, batch=16, imgsz=640, save=True, cache=False, device=None, workers=8, project=None, name=None, exist_ok=False, pretrained=False, optimizer=SGD, verbose=False, seed=0, deterministic=True, single_cls=False, image_weights=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, show=False, save_txt=False, save_conf=False, save_crop=False, hide_labels=False, hide_conf=False, vid_stride=1, line_thickness=3, visualize=False, augment=False, agnostic_nms=False, retina_masks=False, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=17, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, fl_gamma=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, hydra={'output_subdir': None, 'run': {'dir': '.'}}, v5loader=False, save_dir=runs/detect/train2\n",
            "Ultralytics YOLOv8.0.3 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 13.9MB/s]\n",
            "2023-10-23 23:08:46.957315: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-10-23 23:08:46.957367: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-10-23 23:08:46.957405: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-10-23 23:08:46.964361: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-23 23:08:48.319135: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Overriding model.yaml nc=80 with nc=9\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      2320  ultralytics.nn.modules.Conv                  [3, 80, 3, 2]                 \n",
            "  1                  -1  1    115520  ultralytics.nn.modules.Conv                  [80, 160, 3, 2]               \n",
            "  2                  -1  3    436800  ultralytics.nn.modules.C2f                   [160, 160, 3, True]           \n",
            "  3                  -1  1    461440  ultralytics.nn.modules.Conv                  [160, 320, 3, 2]              \n",
            "  4                  -1  6   3281920  ultralytics.nn.modules.C2f                   [320, 320, 6, True]           \n",
            "  5                  -1  1   1844480  ultralytics.nn.modules.Conv                  [320, 640, 3, 2]              \n",
            "  6                  -1  6  13117440  ultralytics.nn.modules.C2f                   [640, 640, 6, True]           \n",
            "  7                  -1  1   3687680  ultralytics.nn.modules.Conv                  [640, 640, 3, 2]              \n",
            "  8                  -1  3   6969600  ultralytics.nn.modules.C2f                   [640, 640, 3, True]           \n",
            "  9                  -1  1   1025920  ultralytics.nn.modules.SPPF                  [640, 640, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 12                  -1  3   7379200  ultralytics.nn.modules.C2f                   [1280, 640, 3]                \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 15                  -1  3   1948800  ultralytics.nn.modules.C2f                   [960, 320, 3]                 \n",
            " 16                  -1  1    922240  ultralytics.nn.modules.Conv                  [320, 320, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 18                  -1  3   7174400  ultralytics.nn.modules.C2f                   [960, 640, 3]                 \n",
            " 19                  -1  1   3687680  ultralytics.nn.modules.Conv                  [640, 640, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.Concat                [1]                           \n",
            " 21                  -1  3   7379200  ultralytics.nn.modules.C2f                   [1280, 640, 3]                \n",
            " 22        [15, 18, 21]  1   8726635  ultralytics.nn.modules.Detect                [9, [320, 640, 640]]          \n",
            "Model summary: 365 layers, 68161275 parameters, 68161259 gradients, 258.2 GFLOPs\n",
            "\n",
            "Transferred 589/595 items from pretrained weights\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Licence-Plate-Detection-using-YOLO-V8/KitchenHygiene-2/train/labels... 5362 images, 0 backgrounds, 0 corrupt: 100% 5362/5362 [00:04<00:00, 1117.24it/s]\n",
            "Signal received. 15 <frame at 0x7b562cc7e260, file '/usr/lib/python3.10/multiprocessing/synchronize.py', line 98, code __exit__>\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Licence-Plate-Detection-using-YOLO-V8/KitchenHygiene-2/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Licence-Plate-Detection-using-YOLO-V8/KitchenHygiene-2/valid/labels... 1449 images, 0 backgrounds, 0 corrupt: 100% 1449/1449 [00:00<00:00, 1727.37it/s]\n",
            "Signal received. 15 <frame at 0x7b5621671e40, file '/usr/lib/python3.10/weakref.py', line 463, code items>\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Licence-Plate-Detection-using-YOLO-V8/KitchenHygiene-2/valid/labels.cache\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/detect/train2\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/10      13.6G      1.405      2.306      1.603          2        640: 100% 336/336 [07:02<00:00,  1.26s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 46/46 [00:50<00:00,  1.09s/it]\n",
            "                   all       1449       2490      0.785      0.647      0.714      0.418\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/10      12.5G       1.31      1.133      1.449          3        640: 100% 336/336 [06:52<00:00,  1.23s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 46/46 [00:49<00:00,  1.07s/it]\n",
            "                   all       1449       2490      0.785      0.611      0.672      0.397\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/10      12.5G      1.422      1.231      1.523          2        640: 100% 336/336 [06:49<00:00,  1.22s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 46/46 [00:48<00:00,  1.05s/it]\n",
            "                   all       1449       2490      0.699      0.557      0.576      0.321\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/10      12.5G      1.479      1.263      1.579          2        640: 100% 336/336 [06:49<00:00,  1.22s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 46/46 [00:48<00:00,  1.05s/it]\n",
            "                   all       1449       2490      0.756      0.547      0.605      0.356\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/10      12.5G      1.467      1.208      1.589          3        640: 100% 336/336 [06:49<00:00,  1.22s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 46/46 [00:48<00:00,  1.06s/it]\n",
            "                   all       1449       2490      0.819      0.641      0.672      0.397\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/10      12.5G       1.39      1.072      1.514          2        640: 100% 336/336 [06:48<00:00,  1.22s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 46/46 [00:48<00:00,  1.06s/it]\n",
            "                   all       1449       2490      0.832      0.674      0.728      0.436\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/10      12.5G      1.325     0.9735      1.457          2        640: 100% 336/336 [06:48<00:00,  1.22s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 46/46 [00:48<00:00,  1.06s/it]\n",
            "                   all       1449       2490      0.869      0.706      0.781      0.469\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/10      12.5G      1.273     0.8674      1.427          2        640: 100% 336/336 [06:48<00:00,  1.22s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 46/46 [00:48<00:00,  1.05s/it]\n",
            "                   all       1449       2490      0.898      0.707      0.789       0.48\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/10      12.5G      1.209     0.7749      1.388          2        640: 100% 336/336 [06:48<00:00,  1.22s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 46/46 [00:48<00:00,  1.06s/it]\n",
            "                   all       1449       2490       0.89      0.717      0.812      0.507\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/10      12.5G      1.153     0.6932       1.34          3        640: 100% 336/336 [06:48<00:00,  1.22s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 46/46 [00:52<00:00,  1.14s/it]\n",
            "                   all       1449       2490      0.773      0.849      0.848       0.55\n",
            "\n",
            "10 epochs completed in 1.296 hours.\n",
            "Optimizer stripped from runs/detect/train2/weights/last.pt, 136.8MB\n",
            "Optimizer stripped from runs/detect/train2/weights/best.pt, 136.8MB\n",
            "\n",
            "Validating runs/detect/train2/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.3 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Fusing layers... \n",
            "Model summary: 268 layers, 68132235 parameters, 0 gradients, 257.4 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 46/46 [00:52<00:00,  1.15s/it]\n",
            "                   all       1449       2490      0.773      0.849      0.848       0.55\n",
            "                     1       1449        131      0.709      0.764       0.83      0.501\n",
            "                 apron       1449        119      0.793          1       0.99      0.695\n",
            "                 glove       1449        125      0.914      0.935      0.979       0.71\n",
            "               hairnet       1449        592      0.917      0.948      0.966      0.613\n",
            "  hemidactylusturcicus       1449          6      0.452       0.42      0.269      0.127\n",
            "                 mouse       1449        554      0.679       0.74       0.76      0.498\n",
            "              no_apron       1449        138      0.701      0.917      0.935      0.604\n",
            "              no_glove       1449        134       0.83       0.94      0.916       0.61\n",
            "            no_hairnet       1449        691      0.961      0.975      0.986      0.595\n",
            "Speed: 0.2ms pre-process, 25.7ms inference, 0.0ms loss, 1.9ms post-process per image\n",
            "Saving runs/detect/train2/predictions.json...\n",
            "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Licence-Plate-Detection-using-YOLO-V8/ultralytics/yolo/v8/detect/predict.py model='/content/Licence-Plate-Detection-using-YOLO-V8/runs/detect/train2/weights/best.pt' source='/content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eh9d2hdFMO0l",
        "outputId": "03aee219-c48c-4a16-a27a-41061acccc69"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-10-24 00:30:35.404928: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-10-24 00:30:35.405015: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-10-24 00:30:35.405058: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-10-24 00:30:35.413957: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-24 00:30:36.769840: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Ultralytics YOLOv8.0.3 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Fusing layers... \n",
            "Model summary: 268 layers, 68132235 parameters, 0 gradients, 257.4 GFLOPs\n",
            "video 1/1 (1/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_apron, 97.5ms\n",
            "video 1/1 (2/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_apron, 1 no_glove, 56.1ms\n",
            "video 1/1 (3/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_apron, 2 no_gloves, 56.9ms\n",
            "video 1/1 (4/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_apron, 2 no_gloves, 54.5ms\n",
            "video 1/1 (5/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_apron, 1 no_glove, 55.8ms\n",
            "video 1/1 (6/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 55.6ms\n",
            "video 1/1 (7/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_apron, 57.0ms\n",
            "video 1/1 (8/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_apron, 2 no_gloves, 54.4ms\n",
            "video 1/1 (9/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 2 no_gloves, 56.4ms\n",
            "video 1/1 (10/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 gloves, 1 hairnet, 1 no_apron, 1 no_glove, 55.1ms\n",
            "video 1/1 (11/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 gloves, 1 hairnet, 1 no_apron, 1 no_glove, 56.4ms\n",
            "video 1/1 (12/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_glove, 55.2ms\n",
            "video 1/1 (13/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 gloves, 1 hairnet, 1 no_glove, 57.6ms\n",
            "video 1/1 (14/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 gloves, 1 hairnet, 1 no_glove, 55.7ms\n",
            "video 1/1 (15/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_glove, 57.7ms\n",
            "video 1/1 (16/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 gloves, 1 hairnet, 1 no_apron, 1 no_glove, 56.0ms\n",
            "video 1/1 (17/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 gloves, 1 hairnet, 1 no_apron, 58.0ms\n",
            "video 1/1 (18/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 56.0ms\n",
            "video 1/1 (19/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 gloves, 1 hairnet, 1 no_apron, 57.3ms\n",
            "video 1/1 (20/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 gloves, 1 hairnet, 1 no_apron, 55.9ms\n",
            "video 1/1 (21/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 gloves, 1 hairnet, 1 no_apron, 57.1ms\n",
            "video 1/1 (22/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 56.2ms\n",
            "video 1/1 (23/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 gloves, 1 hairnet, 1 no_apron, 59.1ms\n",
            "video 1/1 (24/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 56.2ms\n",
            "video 1/1 (25/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 1 no_glove, 58.4ms\n",
            "video 1/1 (26/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 55.4ms\n",
            "video 1/1 (27/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 59.4ms\n",
            "video 1/1 (28/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 54.8ms\n",
            "video 1/1 (29/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 58.0ms\n",
            "video 1/1 (30/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 56.7ms\n",
            "video 1/1 (31/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 2 no_gloves, 56.6ms\n",
            "video 1/1 (32/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 2 no_gloves, 56.1ms\n",
            "video 1/1 (33/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 57.5ms\n",
            "video 1/1 (34/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 58.9ms\n",
            "video 1/1 (35/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 2 no_gloves, 57.3ms\n",
            "video 1/1 (36/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 gloves, 1 hairnet, 1 no_apron, 2 no_gloves, 58.0ms\n",
            "video 1/1 (37/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 2 no_gloves, 58.5ms\n",
            "video 1/1 (38/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 2 no_gloves, 56.2ms\n",
            "video 1/1 (39/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 gloves, 1 hairnet, 1 no_apron, 2 no_gloves, 58.6ms\n",
            "video 1/1 (40/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 gloves, 1 hairnet, 1 no_apron, 2 no_gloves, 56.8ms\n",
            "video 1/1 (41/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 gloves, 1 hairnet, 1 no_apron, 2 no_gloves, 56.5ms\n",
            "video 1/1 (42/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 gloves, 1 hairnet, 1 no_apron, 2 no_gloves, 58.6ms\n",
            "video 1/1 (43/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 gloves, 1 hairnet, 2 no_aprons, 2 no_gloves, 56.3ms\n",
            "video 1/1 (44/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 gloves, 1 hairnet, 2 no_aprons, 2 no_gloves, 56.5ms\n",
            "video 1/1 (45/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 gloves, 1 hairnet, 2 no_aprons, 2 no_gloves, 58.2ms\n",
            "video 1/1 (46/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 gloves, 1 hairnet, 1 no_apron, 2 no_gloves, 57.2ms\n",
            "video 1/1 (47/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 2 no_gloves, 56.9ms\n",
            "video 1/1 (48/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 gloves, 1 hairnet, 1 no_apron, 2 no_gloves, 59.4ms\n",
            "video 1/1 (49/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 1 no_glove, 56.5ms\n",
            "video 1/1 (50/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 1 no_glove, 58.1ms\n",
            "video 1/1 (51/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 3 no_aprons, 1 no_glove, 57.6ms\n",
            "video 1/1 (52/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 2 no_aprons, 1 no_glove, 56.8ms\n",
            "video 1/1 (53/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 3 no_aprons, 1 no_glove, 58.2ms\n",
            "video 1/1 (54/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 2 no_aprons, 1 no_glove, 57.6ms\n",
            "video 1/1 (55/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 3 no_aprons, 1 no_glove, 58.1ms\n",
            "video 1/1 (56/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 3 no_aprons, 2 no_gloves, 59.1ms\n",
            "video 1/1 (57/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 2 no_aprons, 1 no_glove, 57.9ms\n",
            "video 1/1 (58/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 3 no_aprons, 1 no_glove, 58.4ms\n",
            "video 1/1 (59/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 3 no_aprons, 1 no_glove, 58.8ms\n",
            "video 1/1 (60/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 3 no_aprons, 1 no_glove, 57.8ms\n",
            "video 1/1 (61/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 3 no_aprons, 1 no_glove, 58.6ms\n",
            "video 1/1 (62/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 2 no_aprons, 1 no_glove, 57.8ms\n",
            "video 1/1 (63/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 2 no_aprons, 1 no_glove, 57.5ms\n",
            "video 1/1 (64/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 3 no_aprons, 58.9ms\n",
            "video 1/1 (65/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 3 no_aprons, 1 no_glove, 58.8ms\n",
            "video 1/1 (66/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 2 no_aprons, 1 no_glove, 58.0ms\n",
            "video 1/1 (67/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 2 no_aprons, 59.8ms\n",
            "video 1/1 (68/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 2 no_aprons, 56.1ms\n",
            "video 1/1 (69/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 2 no_aprons, 58.1ms\n",
            "video 1/1 (70/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 3 no_aprons, 1 no_glove, 59.0ms\n",
            "video 1/1 (71/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 2 no_aprons, 1 no_glove, 57.8ms\n",
            "video 1/1 (72/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 2 no_aprons, 1 no_glove, 58.1ms\n",
            "video 1/1 (73/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 1 no_glove, 59.0ms\n",
            "video 1/1 (74/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 57.5ms\n",
            "video 1/1 (75/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 1 no_glove, 59.2ms\n",
            "video 1/1 (76/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 1 no_glove, 58.1ms\n",
            "video 1/1 (77/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 3 no_aprons, 57.8ms\n",
            "video 1/1 (78/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 58.5ms\n",
            "video 1/1 (79/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 57.7ms\n",
            "video 1/1 (80/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 gloves, 1 hairnet, 1 no_apron, 58.2ms\n",
            "video 1/1 (81/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 58.2ms\n",
            "video 1/1 (82/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 gloves, 1 hairnet, 1 no_apron, 1 no_glove, 56.4ms\n",
            "video 1/1 (83/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 gloves, 1 hairnet, 1 no_apron, 1 no_glove, 58.4ms\n",
            "video 1/1 (84/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 57.3ms\n",
            "video 1/1 (85/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 58.6ms\n",
            "video 1/1 (86/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_apron, 1 no_glove, 56.3ms\n",
            "video 1/1 (87/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_apron, 1 no_glove, 59.1ms\n",
            "video 1/1 (88/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 2 no_aprons, 1 no_glove, 56.7ms\n",
            "video 1/1 (89/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 3 no_aprons, 1 no_glove, 58.7ms\n",
            "video 1/1 (90/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 3 no_aprons, 1 no_glove, 56.9ms\n",
            "video 1/1 (91/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 3 no_aprons, 1 no_glove, 56.7ms\n",
            "video 1/1 (92/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 3 no_aprons, 1 no_glove, 56.0ms\n",
            "video 1/1 (93/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 2 no_aprons, 1 no_glove, 57.1ms\n",
            "video 1/1 (94/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_apron, 1 no_glove, 57.2ms\n",
            "video 1/1 (95/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_apron, 1 no_glove, 58.7ms\n",
            "video 1/1 (96/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_apron, 1 no_glove, 56.1ms\n",
            "video 1/1 (97/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_apron, 1 no_glove, 58.6ms\n",
            "video 1/1 (98/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_apron, 1 no_glove, 55.9ms\n",
            "video 1/1 (99/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_apron, 1 no_glove, 59.2ms\n",
            "video 1/1 (100/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_apron, 1 no_glove, 57.4ms\n",
            "video 1/1 (101/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_apron, 1 no_glove, 58.4ms\n",
            "video 1/1 (102/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_apron, 1 no_glove, 56.4ms\n",
            "video 1/1 (103/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_apron, 1 no_glove, 57.8ms\n",
            "video 1/1 (104/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_apron, 1 no_glove, 57.1ms\n",
            "video 1/1 (105/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_apron, 1 no_glove, 57.1ms\n",
            "video 1/1 (106/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_apron, 1 no_glove, 59.4ms\n",
            "video 1/1 (107/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 2 no_aprons, 1 no_glove, 56.6ms\n",
            "video 1/1 (108/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_apron, 1 no_glove, 58.7ms\n",
            "video 1/1 (109/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 56.6ms\n",
            "video 1/1 (110/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 2 no_aprons, 1 no_glove, 57.4ms\n",
            "video 1/1 (111/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 2 no_aprons, 1 no_glove, 55.4ms\n",
            "video 1/1 (112/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 2 no_aprons, 1 no_glove, 56.6ms\n",
            "video 1/1 (113/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 2 no_aprons, 1 no_glove, 58.1ms\n",
            "video 1/1 (114/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 2 no_aprons, 1 no_glove, 56.7ms\n",
            "video 1/1 (115/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 3 no_aprons, 1 no_glove, 56.2ms\n",
            "video 1/1 (116/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 2 no_aprons, 1 no_glove, 57.0ms\n",
            "video 1/1 (117/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 2 no_aprons, 1 no_glove, 56.2ms\n",
            "video 1/1 (118/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 3 no_aprons, 1 no_glove, 57.6ms\n",
            "video 1/1 (119/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 2 no_aprons, 1 no_glove, 56.0ms\n",
            "video 1/1 (120/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 2 no_aprons, 1 no_glove, 56.6ms\n",
            "video 1/1 (121/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 2 no_aprons, 1 no_glove, 56.3ms\n",
            "video 1/1 (122/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 2 no_aprons, 1 no_glove, 55.5ms\n",
            "video 1/1 (123/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 2 no_aprons, 1 no_glove, 56.9ms\n",
            "video 1/1 (124/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 2 no_aprons, 1 no_glove, 56.7ms\n",
            "video 1/1 (125/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 2 no_aprons, 1 no_glove, 57.5ms\n",
            "video 1/1 (126/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 2 no_aprons, 1 no_glove, 55.4ms\n",
            "video 1/1 (127/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 3 no_aprons, 1 no_glove, 58.0ms\n",
            "video 1/1 (128/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 1 no_glove, 57.4ms\n",
            "video 1/1 (129/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 3 no_aprons, 58.1ms\n",
            "video 1/1 (130/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 3 no_aprons, 58.4ms\n",
            "video 1/1 (131/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 58.2ms\n",
            "video 1/1 (132/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 3 no_aprons, 1 no_glove, 58.1ms\n",
            "video 1/1 (133/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 3 no_aprons, 1 no_glove, 59.0ms\n",
            "video 1/1 (134/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 1 no_glove, 57.6ms\n",
            "video 1/1 (135/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 1 no_glove, 58.4ms\n",
            "video 1/1 (136/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 3 no_aprons, 1 no_glove, 58.9ms\n",
            "video 1/1 (137/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 3 no_aprons, 1 no_glove, 57.5ms\n",
            "video 1/1 (138/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 1 no_glove, 59.0ms\n",
            "video 1/1 (139/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_apron, 1 no_glove, 59.0ms\n",
            "video 1/1 (140/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_apron, 1 no_glove, 58.9ms\n",
            "video 1/1 (141/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 59.2ms\n",
            "video 1/1 (142/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 57.8ms\n",
            "video 1/1 (143/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 58.4ms\n",
            "video 1/1 (144/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 1 no_glove, 58.8ms\n",
            "video 1/1 (145/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 58.5ms\n",
            "video 1/1 (146/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 1 no_glove, 59.6ms\n",
            "video 1/1 (147/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 1 no_glove, 58.7ms\n",
            "video 1/1 (148/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 1 no_glove, 57.6ms\n",
            "video 1/1 (149/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 1 no_glove, 58.8ms\n",
            "video 1/1 (150/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 3 no_aprons, 1 no_glove, 57.9ms\n",
            "video 1/1 (151/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 1 no_glove, 57.5ms\n",
            "video 1/1 (152/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 gloves, 1 hairnet, 3 no_aprons, 58.5ms\n",
            "video 1/1 (153/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 58.1ms\n",
            "video 1/1 (154/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 3 no_aprons, 58.5ms\n",
            "video 1/1 (155/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 1 no_glove, 59.7ms\n",
            "video 1/1 (156/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 57.4ms\n",
            "video 1/1 (157/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 59.3ms\n",
            "video 1/1 (158/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 58.5ms\n",
            "video 1/1 (159/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 57.9ms\n",
            "video 1/1 (160/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 59.2ms\n",
            "video 1/1 (161/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 57.5ms\n",
            "video 1/1 (162/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 1 no_glove, 56.6ms\n",
            "video 1/1 (163/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 58.2ms\n",
            "video 1/1 (164/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 60.1ms\n",
            "video 1/1 (165/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 58.0ms\n",
            "video 1/1 (166/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 1 no_glove, 60.0ms\n",
            "video 1/1 (167/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 55.8ms\n",
            "video 1/1 (168/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 54.8ms\n",
            "video 1/1 (169/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 60.1ms\n",
            "video 1/1 (170/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 3 no_aprons, 1 no_glove, 61.0ms\n",
            "video 1/1 (171/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 57.4ms\n",
            "video 1/1 (172/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 59.7ms\n",
            "video 1/1 (173/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 1 no_glove, 58.7ms\n",
            "video 1/1 (174/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 1 no_glove, 58.0ms\n",
            "video 1/1 (175/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 58.7ms\n",
            "video 1/1 (176/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 58.6ms\n",
            "video 1/1 (177/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 60.2ms\n",
            "video 1/1 (178/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 60.0ms\n",
            "video 1/1 (179/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 57.2ms\n",
            "video 1/1 (180/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 58.6ms\n",
            "video 1/1 (181/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 59.3ms\n",
            "video 1/1 (182/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 57.3ms\n",
            "video 1/1 (183/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 58.9ms\n",
            "video 1/1 (184/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 58.2ms\n",
            "video 1/1 (185/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 58.8ms\n",
            "video 1/1 (186/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 60.2ms\n",
            "video 1/1 (187/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 59.1ms\n",
            "video 1/1 (188/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 3 no_aprons, 1 no_glove, 58.5ms\n",
            "video 1/1 (189/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 59.7ms\n",
            "video 1/1 (190/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 59.0ms\n",
            "video 1/1 (191/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 60.7ms\n",
            "video 1/1 (192/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 59.3ms\n",
            "video 1/1 (193/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 58.9ms\n",
            "video 1/1 (194/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 1 no_glove, 60.2ms\n",
            "video 1/1 (195/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 1 no_glove, 57.3ms\n",
            "video 1/1 (196/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 1 no_glove, 59.3ms\n",
            "video 1/1 (197/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 59.8ms\n",
            "video 1/1 (198/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 58.7ms\n",
            "video 1/1 (199/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 60.6ms\n",
            "video 1/1 (200/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 58.5ms\n",
            "video 1/1 (201/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 58.5ms\n",
            "video 1/1 (202/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 60.1ms\n",
            "video 1/1 (203/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 58.8ms\n",
            "video 1/1 (204/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 59.0ms\n",
            "video 1/1 (205/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 60.5ms\n",
            "video 1/1 (206/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 58.0ms\n",
            "video 1/1 (207/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 59.7ms\n",
            "video 1/1 (208/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 59.7ms\n",
            "video 1/1 (209/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 58.6ms\n",
            "video 1/1 (210/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 59.2ms\n",
            "video 1/1 (211/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 59.2ms\n",
            "video 1/1 (212/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 58.5ms\n",
            "video 1/1 (213/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_glove, 60.5ms\n",
            "video 1/1 (214/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 1 no_apron, 1 no_glove, 60.0ms\n",
            "video 1/1 (215/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_apron, 1 no_glove, 59.2ms\n",
            "video 1/1 (216/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 1 no_glove, 60.2ms\n",
            "video 1/1 (217/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 2 no_aprons, 1 no_glove, 58.4ms\n",
            "video 1/1 (218/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 1 no_glove, 60.4ms\n",
            "video 1/1 (219/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 1 no_glove, 57.4ms\n",
            "video 1/1 (220/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 1 no_glove, 58.9ms\n",
            "video 1/1 (221/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 1 no_glove, 60.2ms\n",
            "video 1/1 (222/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 3 no_aprons, 1 no_glove, 59.0ms\n",
            "video 1/1 (223/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 1 no_glove, 59.4ms\n",
            "video 1/1 (224/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 1 no_glove, 57.6ms\n",
            "video 1/1 (225/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 58.1ms\n",
            "video 1/1 (226/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 60.8ms\n",
            "video 1/1 (227/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 2 no_aprons, 59.3ms\n",
            "video 1/1 (228/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 2 no_aprons, 1 no_glove, 57.4ms\n",
            "video 1/1 (229/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 59.0ms\n",
            "video 1/1 (230/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 59.6ms\n",
            "video 1/1 (231/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 58.4ms\n",
            "video 1/1 (232/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 60.4ms\n",
            "video 1/1 (233/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 58.8ms\n",
            "video 1/1 (234/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 58.8ms\n",
            "video 1/1 (235/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 61.3ms\n",
            "video 1/1 (236/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 hairnet, 59.4ms\n",
            "video 1/1 (237/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 58.3ms\n",
            "video 1/1 (238/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 60.5ms\n",
            "video 1/1 (239/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 58.8ms\n",
            "video 1/1 (240/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 58.9ms\n",
            "video 1/1 (241/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 60.4ms\n",
            "video 1/1 (242/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 58.8ms\n",
            "video 1/1 (243/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 59.2ms\n",
            "video 1/1 (244/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 60.2ms\n",
            "video 1/1 (245/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_apron, 60.9ms\n",
            "video 1/1 (246/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_apron, 59.4ms\n",
            "video 1/1 (247/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_apron, 60.9ms\n",
            "video 1/1 (248/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_apron, 59.5ms\n",
            "video 1/1 (249/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_apron, 59.4ms\n",
            "video 1/1 (250/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_apron, 62.0ms\n",
            "video 1/1 (251/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_apron, 58.4ms\n",
            "video 1/1 (252/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_apron, 60.9ms\n",
            "video 1/1 (253/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 hairnet, 1 no_apron, 59.4ms\n",
            "video 1/1 (254/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 2 no_hairnets, 58.8ms\n",
            "video 1/1 (255/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_hairnet, 60.1ms\n",
            "video 1/1 (256/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_hairnet, 58.7ms\n",
            "video 1/1 (257/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_hairnet, 59.1ms\n",
            "video 1/1 (258/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_hairnet, 60.3ms\n",
            "video 1/1 (259/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_hairnet, 59.7ms\n",
            "video 1/1 (260/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_hairnet, 59.2ms\n",
            "video 1/1 (261/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_apron, 1 no_hairnet, 60.2ms\n",
            "video 1/1 (262/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 no_aprons, 1 no_hairnet, 58.1ms\n",
            "video 1/1 (263/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 no_aprons, 1 no_hairnet, 59.0ms\n",
            "video 1/1 (264/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 no_aprons, 1 no_hairnet, 60.6ms\n",
            "video 1/1 (265/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_apron, 1 no_hairnet, 58.7ms\n",
            "video 1/1 (266/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_apron, 1 no_hairnet, 59.5ms\n",
            "video 1/1 (267/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 no_aprons, 1 no_hairnet, 60.3ms\n",
            "video 1/1 (268/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 no_aprons, 1 no_glove, 1 no_hairnet, 58.0ms\n",
            "video 1/1 (269/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_glove, 1 no_hairnet, 61.5ms\n",
            "video 1/1 (270/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_glove, 1 no_hairnet, 59.2ms\n",
            "video 1/1 (271/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 2 no_aprons, 1 no_glove, 1 no_hairnet, 58.7ms\n",
            "video 1/1 (272/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 no_aprons, 1 no_glove, 1 no_hairnet, 59.1ms\n",
            "video 1/1 (273/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 no_aprons, 1 no_glove, 1 no_hairnet, 58.9ms\n",
            "video 1/1 (274/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 2 no_aprons, 1 no_glove, 1 no_hairnet, 57.8ms\n",
            "video 1/1 (275/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 2 no_aprons, 1 no_glove, 1 no_hairnet, 57.3ms\n",
            "video 1/1 (276/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_glove, 1 no_hairnet, 57.8ms\n",
            "video 1/1 (277/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_hairnet, 58.3ms\n",
            "video 1/1 (278/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 no_aprons, 1 no_hairnet, 60.0ms\n",
            "video 1/1 (279/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 no_aprons, 1 no_hairnet, 57.8ms\n",
            "video 1/1 (280/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_glove, 1 no_hairnet, 60.0ms\n",
            "video 1/1 (281/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_glove, 1 no_hairnet, 59.1ms\n",
            "video 1/1 (282/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_hairnet, 59.5ms\n",
            "video 1/1 (283/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 no_aprons, 1 no_hairnet, 58.2ms\n",
            "video 1/1 (284/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 3 no_aprons, 1 no_hairnet, 59.3ms\n",
            "video 1/1 (285/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 3 no_aprons, 1 no_hairnet, 58.2ms\n",
            "video 1/1 (286/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 no_aprons, 1 no_hairnet, 58.0ms\n",
            "video 1/1 (287/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_apron, 1 no_hairnet, 59.9ms\n",
            "video 1/1 (288/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_apron, 1 no_hairnet, 57.5ms\n",
            "video 1/1 (289/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 2 no_aprons, 1 no_hairnet, 59.6ms\n",
            "video 1/1 (290/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_glove, 1 no_hairnet, 58.2ms\n",
            "video 1/1 (291/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_hairnet, 57.8ms\n",
            "video 1/1 (292/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_hairnet, 58.3ms\n",
            "video 1/1 (293/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_hairnet, 59.6ms\n",
            "video 1/1 (294/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_hairnet, 60.5ms\n",
            "video 1/1 (295/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_hairnet, 58.5ms\n",
            "video 1/1 (296/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_hairnet, 60.6ms\n",
            "video 1/1 (297/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_hairnet, 59.0ms\n",
            "video 1/1 (298/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_glove, 1 no_hairnet, 60.4ms\n",
            "video 1/1 (299/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_glove, 1 no_hairnet, 57.7ms\n",
            "video 1/1 (300/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_glove, 1 no_hairnet, 59.9ms\n",
            "video 1/1 (301/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 2 no_gloves, 1 no_hairnet, 57.6ms\n",
            "video 1/1 (302/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 2 no_gloves, 1 no_hairnet, 57.9ms\n",
            "video 1/1 (303/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 2 no_gloves, 1 no_hairnet, 55.3ms\n",
            "video 1/1 (304/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 2 no_gloves, 1 no_hairnet, 60.4ms\n",
            "video 1/1 (305/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 no_gloves, 1 no_hairnet, 58.4ms\n",
            "video 1/1 (306/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 no_gloves, 1 no_hairnet, 58.6ms\n",
            "video 1/1 (307/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 no_gloves, 1 no_hairnet, 58.4ms\n",
            "video 1/1 (308/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 2 no_gloves, 1 no_hairnet, 58.3ms\n",
            "video 1/1 (309/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 2 no_gloves, 1 no_hairnet, 57.8ms\n",
            "video 1/1 (310/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_apron, 2 no_gloves, 1 no_hairnet, 59.5ms\n",
            "video 1/1 (311/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_apron, 2 no_gloves, 1 no_hairnet, 57.5ms\n",
            "video 1/1 (312/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_apron, 2 no_gloves, 1 no_hairnet, 57.9ms\n",
            "video 1/1 (313/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 2 no_gloves, 1 no_hairnet, 59.0ms\n",
            "video 1/1 (314/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_apron, 2 no_gloves, 1 no_hairnet, 58.1ms\n",
            "video 1/1 (315/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 no_gloves, 1 no_hairnet, 59.6ms\n",
            "video 1/1 (316/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 2 no_gloves, 1 no_hairnet, 57.8ms\n",
            "video 1/1 (317/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 no_gloves, 1 no_hairnet, 60.8ms\n",
            "video 1/1 (318/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 no_gloves, 1 no_hairnet, 57.8ms\n",
            "video 1/1 (319/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 no_gloves, 1 no_hairnet, 59.9ms\n",
            "video 1/1 (320/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 no_gloves, 1 no_hairnet, 59.2ms\n",
            "video 1/1 (321/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 no_aprons, 2 no_gloves, 1 no_hairnet, 59.1ms\n",
            "video 1/1 (322/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 no_aprons, 2 no_gloves, 1 no_hairnet, 59.8ms\n",
            "video 1/1 (323/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 no_aprons, 2 no_gloves, 1 no_hairnet, 58.7ms\n",
            "video 1/1 (324/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 no_aprons, 2 no_gloves, 1 no_hairnet, 60.8ms\n",
            "video 1/1 (325/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 no_aprons, 1 no_glove, 1 no_hairnet, 57.8ms\n",
            "video 1/1 (326/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 no_aprons, 1 no_glove, 1 no_hairnet, 60.7ms\n",
            "video 1/1 (327/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_glove, 1 no_hairnet, 59.6ms\n",
            "video 1/1 (328/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_glove, 1 no_hairnet, 59.1ms\n",
            "video 1/1 (329/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_glove, 1 no_hairnet, 62.2ms\n",
            "video 1/1 (330/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 2 no_aprons, 1 no_glove, 1 no_hairnet, 58.9ms\n",
            "video 1/1 (331/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 2 no_aprons, 1 no_hairnet, 60.2ms\n",
            "video 1/1 (332/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_glove, 1 no_hairnet, 60.0ms\n",
            "video 1/1 (333/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 2 no_gloves, 1 no_hairnet, 59.2ms\n",
            "video 1/1 (334/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_apron, 1 no_hairnet, 62.3ms\n",
            "video 1/1 (335/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_apron, 1 no_hairnet, 57.5ms\n",
            "video 1/1 (336/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_apron, 1 no_hairnet, 60.2ms\n",
            "video 1/1 (337/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_apron, 1 no_hairnet, 59.8ms\n",
            "video 1/1 (338/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_apron, 1 no_glove, 1 no_hairnet, 59.2ms\n",
            "video 1/1 (339/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_apron, 1 no_glove, 1 no_hairnet, 61.2ms\n",
            "video 1/1 (340/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_apron, 1 no_glove, 1 no_hairnet, 59.2ms\n",
            "video 1/1 (341/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_apron, 2 no_gloves, 1 no_hairnet, 59.7ms\n",
            "video 1/1 (342/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_apron, 1 no_glove, 1 no_hairnet, 58.8ms\n",
            "video 1/1 (343/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_apron, 1 no_glove, 1 no_hairnet, 61.0ms\n",
            "video 1/1 (344/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_glove, 1 no_hairnet, 59.4ms\n",
            "video 1/1 (345/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_glove, 1 no_hairnet, 59.9ms\n",
            "video 1/1 (346/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 2 no_aprons, 2 no_gloves, 1 no_hairnet, 59.7ms\n",
            "video 1/1 (347/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_apron, 1 no_glove, 1 no_hairnet, 58.0ms\n",
            "video 1/1 (348/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_hairnet, 60.8ms\n",
            "video 1/1 (349/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_glove, 1 no_hairnet, 60.4ms\n",
            "video 1/1 (350/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_hairnet, 59.2ms\n",
            "video 1/1 (351/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_hairnet, 62.1ms\n",
            "video 1/1 (352/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_glove, 1 no_hairnet, 60.2ms\n",
            "video 1/1 (353/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_apron, 1 no_hairnet, 60.0ms\n",
            "video 1/1 (354/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 no_aprons, 1 no_glove, 1 no_hairnet, 58.4ms\n",
            "video 1/1 (355/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 no_aprons, 2 no_gloves, 1 no_hairnet, 59.9ms\n",
            "video 1/1 (356/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 no_aprons, 1 no_hairnet, 60.5ms\n",
            "video 1/1 (357/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_apron, 1 no_glove, 1 no_hairnet, 58.9ms\n",
            "video 1/1 (358/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 no_aprons, 1 no_glove, 1 no_hairnet, 61.4ms\n",
            "video 1/1 (359/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 no_aprons, 1 no_glove, 1 no_hairnet, 59.9ms\n",
            "video 1/1 (360/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_glove, 1 no_hairnet, 60.4ms\n",
            "video 1/1 (361/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 no_aprons, 1 no_glove, 1 no_hairnet, 60.9ms\n",
            "video 1/1 (362/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_glove, 1 no_hairnet, 59.1ms\n",
            "video 1/1 (363/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_hairnet, 60.5ms\n",
            "video 1/1 (364/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_hairnet, 65.0ms\n",
            "video 1/1 (365/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_glove, 1 no_hairnet, 59.7ms\n",
            "video 1/1 (366/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 no_aprons, 1 no_hairnet, 61.2ms\n",
            "video 1/1 (367/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_glove, 1 no_hairnet, 64.6ms\n",
            "video 1/1 (368/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_glove, 1 no_hairnet, 59.6ms\n",
            "video 1/1 (369/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_glove, 1 no_hairnet, 60.2ms\n",
            "video 1/1 (370/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_glove, 1 no_hairnet, 60.8ms\n",
            "video 1/1 (371/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_glove, 1 no_hairnet, 59.0ms\n",
            "video 1/1 (372/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_apron, 1 no_hairnet, 60.4ms\n",
            "video 1/1 (373/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_hairnet, 62.2ms\n",
            "video 1/1 (374/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_hairnet, 58.9ms\n",
            "video 1/1 (375/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_glove, 1 no_hairnet, 61.2ms\n",
            "video 1/1 (376/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_glove, 1 no_hairnet, 59.9ms\n",
            "video 1/1 (377/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 4 no_gloves, 1 no_hairnet, 59.9ms\n",
            "video 1/1 (378/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_glove, 1 no_hairnet, 61.3ms\n",
            "video 1/1 (379/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_glove, 1 no_hairnet, 60.0ms\n",
            "video 1/1 (380/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_glove, 1 no_hairnet, 61.6ms\n",
            "video 1/1 (381/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_glove, 1 no_hairnet, 58.8ms\n",
            "video 1/1 (382/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_hairnet, 61.5ms\n",
            "video 1/1 (383/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_glove, 1 no_hairnet, 60.1ms\n",
            "video 1/1 (384/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_glove, 1 no_hairnet, 59.8ms\n",
            "video 1/1 (385/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_glove, 1 no_hairnet, 60.7ms\n",
            "video 1/1 (386/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 2 no_aprons, 1 no_glove, 1 no_hairnet, 59.0ms\n",
            "video 1/1 (387/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_apron, 1 no_glove, 1 no_hairnet, 61.1ms\n",
            "video 1/1 (388/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_apron, 1 no_glove, 1 no_hairnet, 59.5ms\n",
            "video 1/1 (389/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_glove, 1 no_hairnet, 61.3ms\n",
            "video 1/1 (390/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 glove, 1 no_apron, 1 no_hairnet, 61.0ms\n",
            "video 1/1 (391/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_hairnet, 60.4ms\n",
            "video 1/1 (392/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_hairnet, 60.8ms\n",
            "video 1/1 (393/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_hairnet, 60.6ms\n",
            "video 1/1 (394/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_hairnet, 60.3ms\n",
            "video 1/1 (395/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_glove, 1 no_hairnet, 60.6ms\n",
            "video 1/1 (396/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 2 no_aprons, 1 no_glove, 1 no_hairnet, 61.5ms\n",
            "video 1/1 (397/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_glove, 1 no_hairnet, 57.8ms\n",
            "video 1/1 (398/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 2 no_gloves, 1 no_hairnet, 60.6ms\n",
            "video 1/1 (399/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 4 no_gloves, 1 no_hairnet, 60.4ms\n",
            "video 1/1 (400/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_glove, 1 no_hairnet, 58.8ms\n",
            "video 1/1 (401/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_hairnet, 61.2ms\n",
            "video 1/1 (402/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_glove, 1 no_hairnet, 60.2ms\n",
            "video 1/1 (403/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_hairnet, 61.6ms\n",
            "video 1/1 (404/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_glove, 1 no_hairnet, 61.1ms\n",
            "video 1/1 (405/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_hairnet, 60.3ms\n",
            "video 1/1 (406/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_hairnet, 61.7ms\n",
            "video 1/1 (407/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_hairnet, 60.2ms\n",
            "video 1/1 (408/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_hairnet, 60.6ms\n",
            "video 1/1 (409/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 2 no_hairnets, 59.8ms\n",
            "video 1/1 (410/410) /content/Licence-Plate-Detection-using-YOLO-V8/testvideo.mp4: 640x640 1 no_apron, 1 no_hairnet, 61.2ms\n",
            "Speed: 0.5ms pre-process, 58.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/train3\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Licence-Plate-Detection-using-YOLO-V8/ultralytics/yolo/v8/detect/predict.py model='/content/Licence-Plate-Detection-using-YOLO-V8/runs/detect/train2/weights/best.pt' source='/content/Licence-Plate-Detection-using-YOLO-V8/20231011_090349.jpg'"
      ],
      "metadata": {
        "id": "XFSS5xzGYszt",
        "outputId": "2a56797d-7223-4972-b6f8-ebdee422006b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-10-24 00:49:46.152864: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-10-24 00:49:46.152934: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-10-24 00:49:46.152985: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-10-24 00:49:46.165048: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-10-24 00:49:47.765217: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Ultralytics YOLOv8.0.3 🚀 Python-3.10.12 torch-2.1.0+cu118 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Fusing layers... \n",
            "Model summary: 268 layers, 68132235 parameters, 0 gradients, 257.4 GFLOPs\n",
            "image 1/1 /content/Licence-Plate-Detection-using-YOLO-V8/20231011_090349.jpg: 640x640 2 aprons, 5 gloves, 1 hairnet, 3 no_gloves, 1 no_hairnet, 97.4ms\n",
            "Speed: 0.6ms pre-process, 97.4ms inference, 3.1ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/train4\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}